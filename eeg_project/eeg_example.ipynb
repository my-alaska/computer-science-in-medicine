{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 59093,
     "databundleVersionId": 7469972,
     "sourceType": "competition"
    },
    {
     "sourceId": 7465251,
     "sourceType": "datasetVersion",
     "datasetId": 4317718
    },
    {
     "sourceId": 166350260,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import needed libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:26:43.779631Z",
     "iopub.execute_input": "2024-03-10T19:26:43.780506Z",
     "iopub.status.idle": "2024-03-10T19:26:44.141872Z",
     "shell.execute_reply.started": "2024-03-10T19:26:43.780441Z",
     "shell.execute_reply": "2024-03-10T19:26:44.140923Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:09:44.685694800Z",
     "start_time": "2024-04-03T18:09:43.864686Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup global variables for loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# when working locally set correct paths from the current directory to\n",
    "\n",
    "# directory that contains data from kaggle hms\n",
    "INPUT_DATA_DIR = \"data\"\n",
    "\n",
    "# directory in which our npy files are/will be stored\n",
    "PROCESSED_DATA_DIR = \"processed_data\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:37:20.570302Z",
     "iopub.execute_input": "2024-03-10T19:37:20.571348Z",
     "iopub.status.idle": "2024-03-10T19:37:20.576332Z",
     "shell.execute_reply.started": "2024-03-10T19:37:20.571307Z",
     "shell.execute_reply": "2024-03-10T19:37:20.575166Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:10:11.301314500Z",
     "start_time": "2024-04-03T18:10:11.279315700Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the metadata"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-09T14:46:01.191481Z",
     "iopub.execute_input": "2024-03-09T14:46:01.191866Z",
     "iopub.status.idle": "2024-03-09T14:46:01.205753Z",
     "shell.execute_reply.started": "2024-03-09T14:46:01.191832Z",
     "shell.execute_reply": "2024-03-09T14:46:01.204294Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_meta = pd.read_csv(INPUT_DATA_DIR + \"/train.csv\")\n",
    "test_meta = pd.read_csv(INPUT_DATA_DIR + \"/test.csv\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:26:46.557489Z",
     "iopub.execute_input": "2024-03-10T19:26:46.557861Z",
     "iopub.status.idle": "2024-03-10T19:26:46.804895Z",
     "shell.execute_reply.started": "2024-03-10T19:26:46.557833Z",
     "shell.execute_reply": "2024-03-10T19:26:46.804009Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:10:12.272962400Z",
     "start_time": "2024-04-03T18:10:12.180960100Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# take a parquet dataframe and compute correct values for each column\n",
    "# we want columns such as \"Fp1-F7\" as can be seen in /example_figures\n",
    "def extract_parquet(parquet_data):\n",
    "    parquet_data[\"Fp1-F7\"] = parquet_data[\"Fp1\"] - parquet_data[\"F7\"]\n",
    "    parquet_data[\"F7-T3\"] = parquet_data[\"F7\"] - parquet_data[\"T3\"]\n",
    "    parquet_data[\"T3-T5\"] = parquet_data[\"T3\"] - parquet_data[\"T5\"]\n",
    "    parquet_data[\"T5-O1\"] = parquet_data[\"T5\"] - parquet_data[\"O1\"]\n",
    "\n",
    "    parquet_data[\"Fp2-F8\"] = parquet_data[\"Fp2\"] - parquet_data[\"F8\"]\n",
    "    parquet_data[\"F8-T4\"] = parquet_data[\"F8\"] - parquet_data[\"T4\"]\n",
    "    parquet_data[\"T4-T6\"] = parquet_data[\"T4\"] - parquet_data[\"T6\"]\n",
    "    parquet_data[\"T6-O2\"] = parquet_data[\"T6\"] - parquet_data[\"O2\"]\n",
    "\n",
    "    parquet_data[\"Fp1-F3\"] = parquet_data[\"Fp1\"] - parquet_data[\"F3\"]\n",
    "    parquet_data[\"F3-C3\"] = parquet_data[\"F3\"] - parquet_data[\"C3\"]\n",
    "    parquet_data[\"C3-P3\"] = parquet_data[\"C3\"] - parquet_data[\"P3\"]\n",
    "    parquet_data[\"P3-O1\"] = parquet_data[\"P3\"] - parquet_data[\"O1\"]\n",
    "\n",
    "    parquet_data[\"Fp2-F4\"] = parquet_data[\"Fp2\"] - parquet_data[\"F4\"]\n",
    "    parquet_data[\"F4-C4\"] = parquet_data[\"F4\"] - parquet_data[\"C4\"]\n",
    "    parquet_data[\"C4-P4\"] = parquet_data[\"C4\"] - parquet_data[\"P4\"]\n",
    "    parquet_data[\"P4-O2\"] = parquet_data[\"P4\"] - parquet_data[\"O2\"]\n",
    "\n",
    "    parquet_data[\"Fz-Cz\"] = parquet_data[\"Fz\"] - parquet_data[\"Cz\"]\n",
    "    parquet_data[\"Cz-Pz\"] = parquet_data[\"Cz\"] - parquet_data[\"Pz\"]\n",
    "\n",
    "    parquet_data = parquet_data.drop(\n",
    "        [\n",
    "            \"Fp1\",\n",
    "            \"F3\",\n",
    "            \"C3\",\n",
    "            \"P3\",\n",
    "            \"F7\",\n",
    "            \"T3\",\n",
    "            \"T5\",\n",
    "            \"O1\",\n",
    "            \"Fz\",\n",
    "            \"Cz\",\n",
    "            \"Pz\",\n",
    "            \"Fp2\",\n",
    "            \"F4\",\n",
    "            \"C4\",\n",
    "            \"P4\",\n",
    "            \"F8\",\n",
    "            \"T4\",\n",
    "            \"T6\",\n",
    "            \"O2\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    idx = parquet_data.columns[1:].to_list() + [parquet_data.columns[0]]\n",
    "    return parquet_data[idx].values"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:26:46.806346Z",
     "iopub.execute_input": "2024-03-10T19:26:46.806681Z",
     "iopub.status.idle": "2024-03-10T19:26:46.818672Z",
     "shell.execute_reply.started": "2024-03-10T19:26:46.806654Z",
     "shell.execute_reply": "2024-03-10T19:26:46.817621Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:10:15.799476800Z",
     "start_time": "2024-04-03T18:10:15.755416Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n0       1628180742           0                       0.0          353733   \n1       1628180742           1                       6.0          353733   \n2       1628180742           2                       8.0          353733   \n3       1628180742           3                      18.0          353733   \n4       1628180742           4                      24.0          353733   \n...            ...         ...                       ...             ...   \n106795   351917269           6                      12.0      2147388374   \n106796   351917269           7                      14.0      2147388374   \n106797   351917269           8                      16.0      2147388374   \n106798   351917269           9                      18.0      2147388374   \n106799   351917269          10                      20.0      2147388374   \n\n        spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n0                        0                               0.0   127492639   \n1                        1                               6.0  3887563113   \n2                        2                               8.0  1142670488   \n3                        3                              18.0  2718991173   \n4                        4                              24.0  3080632009   \n...                    ...                               ...         ...   \n106795                   6                              12.0  4195677307   \n106796                   7                              14.0   290896675   \n106797                   8                              16.0   461435451   \n106798                   9                              18.0  3786213131   \n106799                  10                              20.0  3642716176   \n\n        patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n0            42516          Seizure             3         0         0   \n1            42516          Seizure             3         0         0   \n2            42516          Seizure             3         0         0   \n3            42516          Seizure             3         0         0   \n4            42516          Seizure             3         0         0   \n...            ...              ...           ...       ...       ...   \n106795       10351             LRDA             0         0         0   \n106796       10351             LRDA             0         0         0   \n106797       10351             LRDA             0         0         0   \n106798       10351             LRDA             0         0         0   \n106799       10351             LRDA             0         0         0   \n\n        lrda_vote  grda_vote  other_vote  \n0               0          0           0  \n1               0          0           0  \n2               0          0           0  \n3               0          0           0  \n4               0          0           0  \n...           ...        ...         ...  \n106795          3          0           0  \n106796          3          0           0  \n106797          3          0           0  \n106798          3          0           0  \n106799          3          0           0  \n\n[106800 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eeg_id</th>\n      <th>eeg_sub_id</th>\n      <th>eeg_label_offset_seconds</th>\n      <th>spectrogram_id</th>\n      <th>spectrogram_sub_id</th>\n      <th>spectrogram_label_offset_seconds</th>\n      <th>label_id</th>\n      <th>patient_id</th>\n      <th>expert_consensus</th>\n      <th>seizure_vote</th>\n      <th>lpd_vote</th>\n      <th>gpd_vote</th>\n      <th>lrda_vote</th>\n      <th>grda_vote</th>\n      <th>other_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1628180742</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>353733</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>127492639</td>\n      <td>42516</td>\n      <td>Seizure</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1628180742</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>353733</td>\n      <td>1</td>\n      <td>6.0</td>\n      <td>3887563113</td>\n      <td>42516</td>\n      <td>Seizure</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1628180742</td>\n      <td>2</td>\n      <td>8.0</td>\n      <td>353733</td>\n      <td>2</td>\n      <td>8.0</td>\n      <td>1142670488</td>\n      <td>42516</td>\n      <td>Seizure</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1628180742</td>\n      <td>3</td>\n      <td>18.0</td>\n      <td>353733</td>\n      <td>3</td>\n      <td>18.0</td>\n      <td>2718991173</td>\n      <td>42516</td>\n      <td>Seizure</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1628180742</td>\n      <td>4</td>\n      <td>24.0</td>\n      <td>353733</td>\n      <td>4</td>\n      <td>24.0</td>\n      <td>3080632009</td>\n      <td>42516</td>\n      <td>Seizure</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106795</th>\n      <td>351917269</td>\n      <td>6</td>\n      <td>12.0</td>\n      <td>2147388374</td>\n      <td>6</td>\n      <td>12.0</td>\n      <td>4195677307</td>\n      <td>10351</td>\n      <td>LRDA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106796</th>\n      <td>351917269</td>\n      <td>7</td>\n      <td>14.0</td>\n      <td>2147388374</td>\n      <td>7</td>\n      <td>14.0</td>\n      <td>290896675</td>\n      <td>10351</td>\n      <td>LRDA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106797</th>\n      <td>351917269</td>\n      <td>8</td>\n      <td>16.0</td>\n      <td>2147388374</td>\n      <td>8</td>\n      <td>16.0</td>\n      <td>461435451</td>\n      <td>10351</td>\n      <td>LRDA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106798</th>\n      <td>351917269</td>\n      <td>9</td>\n      <td>18.0</td>\n      <td>2147388374</td>\n      <td>9</td>\n      <td>18.0</td>\n      <td>3786213131</td>\n      <td>10351</td>\n      <td>LRDA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106799</th>\n      <td>351917269</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>2147388374</td>\n      <td>10</td>\n      <td>20.0</td>\n      <td>3642716176</td>\n      <td>10351</td>\n      <td>LRDA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>106800 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the data and labels for training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data_and_labels():\n",
    "    if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "        os.mkdir(PROCESSED_DATA_DIR)\n",
    "\n",
    "    # if you have enough ram you can extract all metada rows\n",
    "    # N_ROWS = train_meta.shape[0] # uncomment this line if you feel confident\n",
    "    N_ROWS = (\n",
    "        train_meta[\"eeg_id\"].unique().shape[0]\n",
    "    )  # comment this line out if you feel confident\n",
    "\n",
    "    if not os.path.exists(PROCESSED_DATA_DIR + \"/data_eeg.npz\") or not os.path.exists(\n",
    "        PROCESSED_DATA_DIR + \"/labels_eeg.npz\"\n",
    "    ):\n",
    "        data_eeg = np.empty(\n",
    "            (N_ROWS, 10000, 19), dtype=np.float32\n",
    "        )  # 50 seconds long eeg data\n",
    "        labels_eeg = np.empty((N_ROWS, 6), dtype=np.float32)  # labels to predict\n",
    "        nan_rows = 0\n",
    "        i = 0\n",
    "        # each eeg id contains several entries\n",
    "        # we extract them here to make separate entities for training\n",
    "        for eeg_id in train_meta[\"eeg_id\"].unique():\n",
    "            # read the parquet file\n",
    "            parquet_data = pd.read_parquet(\n",
    "                INPUT_DATA_DIR + \"/train_eegs/\" + str(eeg_id) + \".parquet\"\n",
    "            )\n",
    "\n",
    "            # extract the data\n",
    "            parquet_data = extract_parquet(parquet_data)\n",
    "\n",
    "            # get entries corresponding to the processed parquet\n",
    "            sub_train_meta = train_meta.loc[train_meta[\"eeg_id\"] == eeg_id]\n",
    "\n",
    "            # extract needed columns\n",
    "            sub_ids = sub_train_meta[\"eeg_sub_id\"]\n",
    "            offsets = sub_train_meta[\"eeg_label_offset_seconds\"]\n",
    "            labels = sub_train_meta[\n",
    "                [\n",
    "                    \"seizure_vote\",\n",
    "                    \"lpd_vote\",\n",
    "                    \"gpd_vote\",\n",
    "                    \"lrda_vote\",\n",
    "                    \"grda_vote\",\n",
    "                    \"other_vote\",\n",
    "                ]\n",
    "            ].values\n",
    "\n",
    "            # create eeg data and label for each metadata entry\n",
    "            for sub_id, offset, label in zip(sub_ids, offsets, labels):\n",
    "                d = parquet_data[int(offset * 200) : int((50 + offset) * 200)]\n",
    "                if np.isnan(d).sum() > 0:\n",
    "                    nan_rows += 1\n",
    "                    continue\n",
    "                data_eeg[i] = parquet_data[int(offset * 200) : int((50 + offset) * 200)]\n",
    "                labels_eeg[i] = label / label.sum()\n",
    "                i += 1\n",
    "                # if you have enough ram you can finish this loop\n",
    "                break  # comment this line out if you feel confident\n",
    "\n",
    "        labels_eeg = labels_eeg[:-nan_rows]\n",
    "        data_eeg = data_eeg[:-nan_rows]\n",
    "\n",
    "        np.savez(\n",
    "            PROCESSED_DATA_DIR + \"/labels_eeg\",\n",
    "            labels_eeg[:-nan_rows],\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "        np.savez(\n",
    "            PROCESSED_DATA_DIR + \"/data_eeg\", data_eeg[:-nan_rows], allow_pickle=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"loading\")\n",
    "        data_eeg = np.load(PROCESSED_DATA_DIR + \"/data_eeg.npz\", allow_pickle=True)[\n",
    "            \"arr_0\"\n",
    "        ]\n",
    "        labels_eeg = np.load(PROCESSED_DATA_DIR + \"/labels_eeg.npz\", allow_pickle=True)[\n",
    "            \"arr_0\"\n",
    "        ]\n",
    "    return data_eeg, labels_eeg"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:37:30.688728Z",
     "iopub.execute_input": "2024-03-10T19:37:30.689118Z",
     "iopub.status.idle": "2024-03-10T19:37:30.705980Z",
     "shell.execute_reply.started": "2024-03-10T19:37:30.689085Z",
     "shell.execute_reply": "2024-03-10T19:37:30.704996Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a data loader, preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup global variables for datalodar and preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:37:32.829968Z",
     "iopub.execute_input": "2024-03-10T19:37:32.830844Z",
     "iopub.status.idle": "2024-03-10T19:37:32.835523Z",
     "shell.execute_reply.started": "2024-03-10T19:37:32.830810Z",
     "shell.execute_reply": "2024-03-10T19:37:32.834507Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a lowpass filter to cut out the high and noisy frequencies"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T18:22:48.423323800Z",
     "start_time": "2024-04-03T18:22:45.647317200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:37:36.075456Z",
     "iopub.execute_input": "2024-03-10T19:37:36.075848Z",
     "iopub.status.idle": "2024-03-10T19:37:36.081920Z",
     "shell.execute_reply.started": "2024-03-10T19:37:36.075818Z",
     "shell.execute_reply": "2024-03-10T19:37:36.080965Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:22:50.141795200Z",
     "start_time": "2024-04-03T18:22:50.054268500Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a HMS dataset class that will help us load the data during the model training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class HMSDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_fold: int = FOLDS - 1,\n",
    "        mode: str = \"train\",\n",
    "    ):\n",
    "        self.kf = KFold(n_splits=FOLDS)\n",
    "        self.num_fold = num_fold\n",
    "\n",
    "        self.X, self.y = get_data_and_labels()\n",
    "        self.train_ids, self.valid_ids = self.__split_data()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "    def __split_data(self):\n",
    "        train_indices, val_indices = list(self.kf.split(self.y))[self.num_fold]\n",
    "        return train_indices, val_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.train_ids)\n",
    "        else:\n",
    "            return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.__retrieve_data(index)\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(\n",
    "            y, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def __retrieve_data(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            X = self.X[self.train_ids[index]]\n",
    "            y = self.y[self.train_ids[index]]\n",
    "        else:\n",
    "            X = self.X[self.valid_ids[index]]\n",
    "            y = self.y[self.valid_ids[index]]\n",
    "\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "        X = butter_lowpass_filter(X)\n",
    "        return X, y\n",
    "\n",
    "    def train(self):\n",
    "        self.mode = \"train\"\n",
    "\n",
    "    def eval(self):\n",
    "        self.mode = \"eval\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:37:36.929519Z",
     "iopub.execute_input": "2024-03-10T19:37:36.930195Z",
     "iopub.status.idle": "2024-03-10T19:37:36.941509Z",
     "shell.execute_reply.started": "2024-03-10T19:37:36.930162Z",
     "shell.execute_reply": "2024-03-10T19:37:36.940516Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize the dataset and dataloader!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = HMSDataset()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T19:38:08.471727Z",
     "iopub.execute_input": "2024-03-10T19:38:08.472111Z",
     "iopub.status.idle": "2024-03-10T19:49:19.672417Z",
     "shell.execute_reply.started": "2024-03-10T19:38:08.472081Z",
     "shell.execute_reply": "2024-03-10T19:49:19.671132Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride, padding, downsampling\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, kernels=[3, 5, 7, 9], in_channels=19, fixed_kernel_size=17, num_classes=6\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size, stride=1, padding=fixed_kernel_size // 2\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=False)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features=424, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(self, kernel_size, stride, blocks=9, padding=0):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        #         out = self.dropout(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        new_out = self.dropout(new_out)\n",
    "        result = self.fc(new_out)\n",
    "\n",
    "        return result"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training (TBD)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T16:13:47.666106Z",
     "iopub.execute_input": "2024-03-10T16:13:47.666559Z",
     "iopub.status.idle": "2024-03-10T16:13:47.673670Z",
     "shell.execute_reply.started": "2024-03-10T16:13:47.666526Z",
     "shell.execute_reply": "2024-03-10T16:13:47.672143Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
